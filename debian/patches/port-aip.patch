--- a/Makefile
+++ b/Makefile
@@ -9,7 +9,8 @@
 
 CFLAGS_MODULE += -DUSE_PI_LED_ENABLE=1 -DIFS_DEB9
 obj-y := rdmavt/ \
-	hfi1/
+	hfi1/ \
+	ib_ipoib/
 
 else
 #normal makefile
--- a/ib_ipoib/Makefile
+++ b/ib_ipoib/Makefile
@@ -28,7 +28,7 @@
 	$(MAKE) -C $(KDIR) M=$$PWD clean
 
 install:
-	$(MAKE) INSTALL_MOD_DIR=updates -C $(KDIR) M=$$PWD modules_install
+	$(MAKE) INSTALL_MOD_PATH=$(DESTDIR) INSTALL_MOD_DIR=updates/ifs-kernel-updates -C $(KDIR) M=$$PWD modules_install
 
 
 endif
--- a/ib_ipoib/ipoib_main.c
+++ b/ib_ipoib/ipoib_main.c
@@ -50,7 +50,9 @@
 #include <net/addrconf.h>
 #include <linux/inetdevice.h>
 #include <rdma/ib_cache.h>
-
+#if defined(IFS_DEB9)
+#include "../hfi1/hfi1_netdev.h"
+#endif
 #define DRV_VERSION "1.0.0"
 
 const char ipoib_driver_version[] = DRV_VERSION;
@@ -262,6 +264,7 @@
 
 	new_mtu = min(priv->mcast_mtu, priv->admin_mtu);
 
+#ifndef IFS_DEB9
 	if (get_ndo_ext(priv->rn_ops, ndo_change_mtu)) {
 		bool carrier_status = netif_carrier_ok(dev);
 
@@ -275,12 +278,19 @@
 	} else {
 		dev->mtu = new_mtu;
 	}
-
+#else
+	dev->mtu = new_mtu;
+#endif
 	return ret;
 }
 
-static void ipoib_get_stats(struct net_device *dev,
-			    struct rtnl_link_stats64 *stats)
+#ifdef IFS_DEB9
+static struct rtnl_link_stats64*
+#else
+static void
+#endif
+ipoib_get_stats(struct net_device *dev,
+		struct rtnl_link_stats64 *stats)
 {
 	struct ipoib_dev_priv *priv = ipoib_priv(dev);
 
@@ -288,6 +298,9 @@
 		priv->rn_ops->ndo_get_stats64(dev, stats);
 	else
 		netdev_stats_to_stats64(stats, &dev->stats);
+#ifdef IFS_DEB9
+	return stats;
+#endif
 }
 
 /* Called with an RCU read lock taken */
@@ -306,7 +319,11 @@
 		if (!in_dev)
 			return false;
 
-		ret_addr = inet_confirm_addr(in_dev, 0,
+		ret_addr = inet_confirm_addr(
+#ifdef IFS_DEB9
+					     net,
+#endif
+					     in_dev, 0,
 					     addr_in->sin_addr.s_addr,
 					     RT_SCOPE_HOST);
 		in_dev_put(in_dev);
@@ -708,6 +725,79 @@
 	spin_unlock_irq(&priv->lock);
 }
 
+#ifdef IFS_DEB9
+struct classport_info_context {
+        struct ipoib_dev_priv   *priv;
+        struct completion       done;
+        struct ib_sa_query      *sa_query;
+};
+
+static void classport_info_query_cb(int status, struct ib_class_port_info *rec,
+                                    void *context)
+{
+        struct classport_info_context *cb_ctx = context;
+        struct ipoib_dev_priv *priv;
+
+        WARN_ON(!context);
+
+        priv = cb_ctx->priv;
+
+        if (status || !rec) {
+                pr_debug("device: %s failed query classport_info status: %d\n",
+                         priv->dev->name, status);
+                /* keeps the default, will try next mcast_restart */
+                priv->sm_fullmember_sendonly_support = false;
+                goto out;
+        }
+
+        if (ib_get_cpi_capmask2(rec) &
+            IB_SA_CAP_MASK2_SENDONLY_FULL_MEM_SUPPORT) {
+                pr_debug("device: %s enabled fullmember-sendonly for sendonly MCG\n",
+                         priv->dev->name);
+                priv->sm_fullmember_sendonly_support = true;
+        } else {
+                pr_debug("device: %s disabled fullmember-sendonly for sendonly MCG\n",
+                         priv->dev->name);
+                priv->sm_fullmember_sendonly_support = false;
+        }
+
+out:
+        complete(&cb_ctx->done);
+}
+
+int ipoib_check_sm_sendonly_fullmember_support(struct ipoib_dev_priv *priv)
+{
+        struct classport_info_context *callback_context;
+        int ret;
+
+        callback_context = kmalloc(sizeof(*callback_context), GFP_KERNEL);
+        if (!callback_context)
+                return -ENOMEM;
+
+        callback_context->priv = priv;
+        init_completion(&callback_context->done);
+
+        ret = ib_sa_classport_info_rec_query(&ipoib_sa_client,
+                                             priv->ca, priv->port, 3000,
+                                             GFP_KERNEL,
+                                             classport_info_query_cb,
+                                             callback_context,
+                                             &callback_context->sa_query);
+        if (ret < 0) {
+                pr_info("%s failed to send ib_sa_classport_info query, ret: %d\n",
+                        priv->dev->name, ret);
+                kfree(callback_context);
+                return ret;
+        }
+
+        /* waiting for the callback to finish before returnning */
+        wait_for_completion(&callback_context->done);
+        kfree(callback_context);
+
+        return ret;
+}
+#endif
+
 static void push_pseudo_header(struct sk_buff *skb, const char *daddr)
 {
 	struct ipoib_pseudo_header *phdr;
@@ -772,7 +862,7 @@
 
 	if (!status) {
 		struct rdma_ah_attr av;
-#ifdef IFS_RH75
+#if defined(IFS_RH75) || defined(IFS_DEB9)
 		if (!ib_init_ah_from_path(priv->ca, priv->port,
 					       pathrec, &av))
 
@@ -872,16 +962,18 @@
 {
 	path->dev = priv->dev;
 
+#ifndef IFS_DEB9
 	if (rdma_cap_opa_ah(priv->ca, priv->port))
 		path->pathrec.rec_type = SA_PATH_REC_TYPE_OPA;
 	else
 		path->pathrec.rec_type = SA_PATH_REC_TYPE_IB;
-
+#endif
 	memcpy(path->pathrec.dgid.raw, gid, sizeof(union ib_gid));
 	path->pathrec.sgid	    = priv->local_gid;
 	path->pathrec.pkey	    = cpu_to_be16(priv->pkey);
 	path->pathrec.numb_path     = 1;
 	path->pathrec.traffic_class = priv->broadcast->mcmember.traffic_class;
+
 }
 
 static struct ipoib_path *path_rec_create(struct net_device *dev, void *gid)
@@ -1901,11 +1993,17 @@
 };
 
 static const struct net_device_ops ipoib_netdev_ops_pf = {
+#ifndef IFS_DEB9
 	.ndo_size		 = sizeof(struct net_device_ops),
+#endif
 	.ndo_uninit		 = ipoib_uninit,
 	.ndo_open		 = ipoib_open,
 	.ndo_stop		 = ipoib_stop,
+#ifndef IFS_DEB9
 	.ndo_change_mtu_rh74	 = ipoib_change_mtu,
+#else
+	.ndo_change_mtu	         = ipoib_change_mtu,
+#endif
 	.ndo_fix_features	 = ipoib_fix_features,
 	.ndo_start_xmit		 = ipoib_start_xmit,
 	.ndo_tx_timeout		 = ipoib_timeout,
@@ -1914,7 +2012,11 @@
 	.ndo_set_vf_link_state	 = ipoib_set_vf_link_state,
 	.ndo_get_vf_config	 = ipoib_get_vf_config,
 	.ndo_get_vf_stats	 = ipoib_get_vf_stats,
+#ifdef IFS_DEB9
+	.ndo_set_vf_guid	 = ipoib_set_vf_guid,
+#else
 	.extended.ndo_set_vf_guid	 = ipoib_set_vf_guid,
+#endif
 	.ndo_set_mac_address	 = ipoib_set_mac,
 	.ndo_get_stats64	 = ipoib_get_stats,
 	.ndo_do_ioctl		 = ipoib_ioctl,
@@ -1924,7 +2026,11 @@
 	.ndo_uninit		 = ipoib_uninit,
 	.ndo_open		 = ipoib_open,
 	.ndo_stop		 = ipoib_stop,
+#ifndef IFS_DEB9
 	.ndo_change_mtu_rh74	 = ipoib_change_mtu,
+#else
+	.ndo_change_mtu	         = ipoib_change_mtu,
+#endif
 	.ndo_fix_features	 = ipoib_fix_features,
 	.ndo_start_xmit	 	 = ipoib_start_xmit,
 	.ndo_tx_timeout		 = ipoib_timeout,
@@ -1999,6 +2105,9 @@
 
 	dev = alloc_netdev((int)sizeof(struct rdma_netdev),
 			   name,
+#ifdef IFS_DEB9
+			   NET_NAME_UNKNOWN,
+#endif
 			   setup);
 	if (!dev)
 		return NULL;
@@ -2018,17 +2127,37 @@
 					   const char *name)
 {
 	struct net_device *dev = NULL;
+	struct net_device* (*netdev_alloc)(struct ib_device *device,
+					   u8 port_num,
+					   enum rdma_netdev_t type,
+					   const char *name,
+					   unsigned char name_assign_type,
+					   void (*setup)(struct net_device *));
+
+#if defined(IFS_DEB9)
+	if (rdma_core_cap_opa_port(hca, port))
+		netdev_alloc = hfi1_alloc_rn;
+	else
+		netdev_alloc = NULL;
+#else
+	netdev_alloc = hca->alloc_rdma_netdev;
+#endif
+
+	if (netdev_alloc && ipoib_enhanced_enabled) {
+		pr_info("allocating enhanced IPoIB netdev\n");
+		dev = netdev_alloc(hca, port,
+				   RDMA_NETDEV_IPOIB, name,
+				   0,		/* NET_NAME_UNKNOWN */
+				   ipoib_setup_common);
+
+		if (IS_ERR_OR_NULL(dev))
+			pr_err("failed to allocate enhanced IPoIB netdev\n");
 
-	if (hca->alloc_rdma_netdev && ipoib_enhanced_enabled) {
-		dev = hca->alloc_rdma_netdev(hca, port,
-					     RDMA_NETDEV_IPOIB, name,
-					     0,		/* NET_NAME_UNKNOWN */
-					     ipoib_setup_common);
 		if (IS_ERR_OR_NULL(dev) && PTR_ERR(dev) != -EOPNOTSUPP)
 			return NULL;
 	}
 
-	if (!hca->alloc_rdma_netdev || PTR_ERR(dev) == -EOPNOTSUPP ||
+	if (!netdev_alloc || PTR_ERR(dev) == -EOPNOTSUPP ||
 	    !ipoib_enhanced_enabled)
 		dev = ipoib_create_netdev_default(hca, name, 0, /* NET_NAME_UNKNOWN, */
 						  ipoib_setup_common);
@@ -2473,7 +2602,13 @@
 	 */
 	BUILD_BUG_ON(IPOIB_CM_COPYBREAK > IPOIB_CM_HEAD_SIZE);
 
-	pr_notice("Intel Accelerated IPoIB for RHEL loaded.\n");
+	pr_notice("Intel Accelerated IPoIB for "
+#ifdef IFS_DEB9
+		  "Debian"
+#else
+		  "RHEL"
+#endif
+		  " loaded.\n");
 
 	ret = ipoib_register_debugfs();
 	if (ret)
@@ -2507,8 +2642,12 @@
 		goto err_client;
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
+#ifdef IFS_DEB9
+	register_netdevice_notifier(&ipoib_netdev_notifier);
+#else
 	register_netdevice_notifier_rh(&ipoib_netdev_notifier);
 #endif
+#endif
 	return 0;
 
 err_client:
@@ -2527,8 +2666,12 @@
 static void __exit ipoib_cleanup_module(void)
 {
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
+#ifdef IFS_DEB9
+	unregister_netdevice_notifier(&ipoib_netdev_notifier);
+#else
 	unregister_netdevice_notifier_rh(&ipoib_netdev_notifier);
 #endif
+#endif
 	ipoib_netlink_fini();
 	ib_unregister_client(&ipoib_client);
 	ib_sa_unregister_client(&ipoib_sa_client);
--- a/ib_ipoib/ipoib.h
+++ b/ib_ipoib/ipoib.h
@@ -53,7 +53,7 @@
 #include <rdma/ib_sa.h>
 #include <linux/sched.h>
 
-#include "compat_common.h"
+#include "compat.h"
 
 /* constants */
 
@@ -425,6 +425,18 @@
 	unsigned	   last_send;
 };
 
+#if defined(IFS_DEB9)
+#define sa_path_rec ib_sa_path_rec
+static inline __be32 sa_path_get_dlid(const struct sa_path_rec* rec) {
+	if (ib_is_opa_gid(&rec->dgid))
+		return cpu_to_be32(opa_get_lid_from_gid(&rec->dgid));
+	else
+		return htonl(ntohs(rec->dlid));
+}
+#endif
+
+int ib_init_attr_from_path(const void*, int, const void*, const void*);
+
 struct ipoib_path {
 	struct net_device    *dev;
 	struct sa_path_rec pathrec;
@@ -808,6 +820,11 @@
 
 extern struct ib_sa_client ipoib_sa_client;
 
+#ifdef IFS_DEB9
+int ipoib_check_sm_sendonly_fullmember_support(struct ipoib_dev_priv *priv);
+#endif
+
+
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 extern int ipoib_debug_level;
 
--- a/ib_ipoib/ipoib_ib.c
+++ b/ib_ipoib/ipoib_ib.c
@@ -1085,7 +1085,7 @@
 
 	netif_addr_unlock_bh(priv->dev);
 
-#ifdef IFS_RH75
+#if defined(IFS_RH75) || defined(IFS_DEB9)
         err = ib_find_gid(priv->ca, &search_gid, IB_GID_TYPE_IB,
                           priv->dev, &port, &index);
 #else
--- a/ib_ipoib/ipoib_multicast.c
+++ b/ib_ipoib/ipoib_multicast.c
@@ -46,7 +46,7 @@
 #include <net/dst.h>
 
 #include "ipoib.h"
-#include "compat_common.h"
+#include "compat.h"
 
 #ifdef CONFIG_INFINIBAND_IPOIB_DEBUG
 static int mcast_debug_level;
@@ -279,7 +279,13 @@
 	}
 
 	memset(&av, 0, sizeof(av));
+#if !defined(IFS_DEB9)
+	/*
+	 * rdma_ah_attr does not have a type member in kernel 4.9. ib_is_opa_gid()
+	 * is used to detect opa.
+	 */
 	av.type = rdma_ah_find_type(priv->ca, priv->port);
+#endif
 	rdma_ah_set_dlid(&av, be16_to_cpu(mcast->mcmember.mlid)),
 	rdma_ah_set_port_num(&av, priv->port);
 	rdma_ah_set_sl(&av, mcast->mcmember.sl);
@@ -344,9 +350,14 @@
 	 * because the broadcast group must always be joined first and is always
 	 * re-joined if the SM changes substantially.
 	 */
+#ifdef IFS_DEB9
+	priv->sm_fullmember_sendonly_support = false;
+	ipoib_check_sm_sendonly_fullmember_support(priv);
+#else
 	priv->sm_fullmember_sendonly_support =
 		ib_sa_sendonly_fullmem_support(&ipoib_sa_client,
 					       priv->ca, priv->port);
+#endif
 	/*
 	 * Take rtnl_lock to avoid racing with ipoib_stop() and
 	 * turning the carrier back on while a device is being
--- a/ib_ipoib/ipoib_ethtool.c
+++ b/ib_ipoib/ipoib_ethtool.c
@@ -35,6 +35,7 @@
 #include <linux/netdevice.h>
 
 #include "ipoib.h"
+#include "compat.h"
 
 struct ipoib_stats {
 	char stat_string[ETH_GSTRING_LEN];
@@ -63,7 +64,11 @@
 {
 	struct ipoib_dev_priv *priv = ipoib_priv(netdev);
 
-	ib_get_device_fw_str(priv->ca, drvinfo->fw_version);
+	ib_get_device_fw_str(priv->ca, drvinfo->fw_version
+#ifdef IFS_DEB9
+			     , IB_FW_VERSION_NAME_MAX
+#endif
+			     );
 
 	strlcpy(drvinfo->bus_info, dev_name(priv->ca->dev.parent),
 		sizeof(drvinfo->bus_info));
@@ -99,7 +104,7 @@
 	    coal->rx_max_coalesced_frames > 0xffff)
 		return -EINVAL;
 
-#ifdef IFS_RH75
+#if defined(IFS_RH75) || defined(IFS_DEB9)
         ret = ib_modify_cq(priv->recv_cq, coal->rx_max_coalesced_frames,
                            coal->rx_coalesce_usecs);
 #else
@@ -177,7 +182,6 @@
 	case IB_SPEED_EDR:
 		return SPEED_25000;
 	}
-
 	return SPEED_UNKNOWN;
 }
 
@@ -231,5 +235,9 @@
 
 void ipoib_set_ethtool_ops(struct net_device *dev)
 {
+#ifdef IFS_DEB9
+	dev->ethtool_ops = &ipoib_ethtool_ops;
+#else
 	SET_ETHTOOL_OPS(dev, &ipoib_ethtool_ops);
+#endif
 }
--- a/compat/compat.h
+++ b/compat/compat.h
@@ -52,8 +52,31 @@
 #define IB_FW_VERSION_NAME_MAX		   ETHTOOL_FWVERS_LEN
 #define OPA_SM_CLASS_VERSION               0x80
 
+#define SPEED_14000          14000
+
 void pcie_flr(struct pci_dev *dev);
 
 struct ib_ah *rdma_create_ah(struct ib_pd *pd, struct rdma_ah_attr *ah_attr);
 
+static inline void rdma_ah_set_grh(struct rdma_ah_attr *attr,
+				   union ib_gid *dgid, u32 flow_label,
+				   u8 sgid_index, u8 hop_limit,
+				   u8 traffic_class)
+{
+	struct ib_global_route *grh = rdma_ah_retrieve_grh(attr);
+
+	attr->ah_flags = IB_AH_GRH;
+	if (dgid)
+		grh->dgid = *dgid;
+	grh->flow_label = flow_label;
+	grh->sgid_index = sgid_index;
+	grh->hop_limit = hop_limit;
+	grh->traffic_class = traffic_class;
+}
+
+struct net_device;
+int netdev_walk_all_upper_dev_rcu(struct net_device *dev,
+				  int (*fn)(struct net_device *upper_dev,
+					    void *data),
+				  void *data);
 #endif //DEB9_COMPAT
--- a/rdmavt/compat.c
+++ b/rdmavt/compat.c
@@ -258,3 +258,64 @@
 	.alloc_coherent = rvt_dma_alloc_coherent,
 	.free_coherent = rvt_dma_free_coherent
 };
+
+struct netdev_adjacent {
+	struct net_device *dev;
+
+	/* upper master flag, there can only be one master device per list */
+	bool master;
+
+	/* counter for the number of times this device was added to us */
+	u16 ref_nr;
+
+	/* private field for the users */
+	void *private;
+
+	struct list_head list;
+	struct rcu_head rcu;
+};
+
+static struct net_device *netdev_next_upper_dev_rcu(struct net_device *dev,
+						    struct list_head **iter)
+{
+	struct netdev_adjacent *upper;
+
+	WARN_ON_ONCE(!rcu_read_lock_held() && !lockdep_rtnl_is_held());
+
+	upper = list_entry_rcu((*iter)->next, struct netdev_adjacent, list);
+
+	if (&upper->list == &dev->adj_list.upper)
+		return NULL;
+
+	*iter = &upper->list;
+
+	return upper->dev;
+}
+
+int netdev_walk_all_upper_dev_rcu(struct net_device *dev,
+				  int (*fn)(struct net_device *dev,
+					    void *data),
+				  void *data)
+{
+	struct net_device *udev;
+	struct list_head *iter;
+	int ret;
+
+	for (iter = &dev->adj_list.upper,
+	     udev = netdev_next_upper_dev_rcu(dev, &iter);
+	     udev;
+	     udev = netdev_next_upper_dev_rcu(dev, &iter)) {
+		/* first is the upper device itself */
+		ret = fn(udev, data);
+		if (ret)
+			return ret;
+
+		/* then look at all of its upper devices */
+		ret = netdev_walk_all_upper_dev_rcu(udev, fn, data);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(netdev_walk_all_upper_dev_rcu);
