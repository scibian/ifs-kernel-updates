Description: Port rdmavt to kernel 4.9.0
Author: Brian T. Smith <bsmith@systemfabricworks.com>
Forwarded: not-needed
Last-Update: <2019-01-31>
---
This patch header follows DEP-3: http://dep.debian.net/deps/dep3/
--- a/Makefile
+++ b/Makefile
@@ -8,7 +8,7 @@
 #kbuild part of makefile
 
 CFLAGS_MODULE += -DUSE_PI_LED_ENABLE=1 -DIFS_DEB9
-obj-y :=
+obj-y := rdmavt/
 
 else
 #normal makefile
--- a/compat/compat_common.h
+++ b/compat/compat_common.h
@@ -227,6 +227,12 @@
 	u8			src_path_bits;
 };
 
+/*
+ * NOTE: The rdma_ah_attr and associated functions are workarounds for kernels
+ * that lack rdma_ah_attr, which contains type and opa_ah_attr members. This
+ * uses ib_ah_attr as a standin, along with logic to handle the missing data
+ * structures. See also hfi1_make_opa_lid.
+ */
 #define rdma_ah_attr ib_ah_attr
 
 static inline void rdma_ah_set_sl(struct rdma_ah_attr *attr, u8 sl)
@@ -402,7 +408,7 @@
 }
 
 #endif /* NEED_IB_HELPER_FUNCTIONS */
-#define NEED_KTHREAD_HELPER_FUNCTIONS (!defined(IFS_SLES15) && !defined(IFS_SLES15SP1) && !defined(IFS_SLES12SP4) && !defined(IFS_SLES12SP5) && !defined(IFS_RH80) && !defined(IFS_RH81))
+#define NEED_KTHREAD_HELPER_FUNCTIONS (!defined(IFS_SLES15) && !defined(IFS_SLES15SP1) && !defined(IFS_SLES12SP4) && !defined(IFS_SLES12SP5) && !defined(IFS_RH80) && !defined(IFS_RH81) && !defined(IFS_DEB9))
 
 #if NEED_KTHREAD_HELPER_FUNCTIONS
 static inline bool kthread_queue_work(struct kthread_worker *worker,
--- a/hfi1/hfi.h
+++ b/hfi1/hfi.h
@@ -739,7 +739,8 @@
 #define MAX_NAME_SIZE 64
 struct hfi1_msix_entry {
 	enum irq_type type;
-#if defined(IFS_RH73) || defined(IFS_RH74) || defined(IFS_RH75) || defined(IFS_RH76) || defined(IFS_SLES12SP2) || defined(IFS_SLES12SP3)
+#if defined(IFS_RH73) || defined(IFS_RH74) || defined(IFS_RH75) || defined(IFS_RH76) || defined(IFS_SLES12SP2) || defined(IFS_SLES12SP3) \
+	|| defined(IFS_DEB9)
 	struct msix_entry msix;
 #endif
 	int irq;
@@ -2628,7 +2629,13 @@
 
 static inline void hfi1_make_opa_lid(struct rdma_ah_attr *attr)
 {
-#if !defined(IFS_RH73) && !defined(IFS_RH74) && !defined(IFS_SLES12SP2) && !defined(IFS_SLES12SP3)
+#if !defined(IFS_RH73) && !defined(IFS_RH74) && !defined(IFS_SLES12SP2) && !defined(IFS_SLES12SP3) \
+	&& !defined(IFS_DEB9)
+	/*
+	 * Note: this code is only used when there is an rdma_ah_attr structure defined
+	 * in ib_verbs.h. It should not be used when rdma_ah_attr is defined as ib_ah_attr.
+	 * See compat_common.h.
+	 */
 	const struct ib_global_route *grh = rdma_ah_read_grh(attr);
 	u32 dlid = rdma_ah_get_dlid(attr);
 
--- a/compat/compat.h
+++ b/compat/compat.h
@@ -44,25 +44,20 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  */
-#if !defined(RH76_COMPAT_H)
-#define RH76_COMPAT_H
+#if !defined(DEB9_COMPAT_H)
+#define DEB9_COMPAT_H
 
-#define CREATE_AH_HAS_UDATA
 #define HAVE_ALLOC_RDMA_NETDEV
 #define NEED_MM_HELPER_FUNCTIONS
+#define NEED_IB_HELPER_FUNCTIONS
 #define HAVE_NOSPEC_H
 
 #include "compat_common.h"
 
-#define __GFP_RECLAIM	(__GFP_WAIT)
-
-#define IB_QP_CREATE_USE_GFP_NOIO (1 << 7)
-
-
 #define IB_FW_VERSION_NAME_MAX			  ETHTOOL_FWVERS_LEN
-#define OPA_CLASS_PORT_INFO_PR_SUPPORT BIT(26)
 
-#define NET_NAME_UNKNOWN 0
+struct ib_ah *rdma_create_ah(struct ib_pd *pd, struct rdma_ah_attr *ah_attr);
+int rdma_destroy_ah(struct ib_ah *ah);
 
 #define rdma_create_ah(a, b, c) rdma_create_ah(a, b)
 #define rdma_destroy_ah(a, b) rdma_destroy_ah(a)
@@ -76,52 +71,8 @@
 	(likely(__range_not_ok(addr, size, user_addr_max()) == 0))
 #define _ib_alloc_device ib_alloc_device
 
-struct hfi1_msix_entry;
-struct hfi1_devdata;
-
 void pcie_flr(struct pci_dev *dev);
 
-int bitmap_print_to_pagebuf(bool list, char *buf,
-			    const unsigned long *maskp, int nmaskbits);
-int debugfs_use_file_start(struct dentry *dentry, int *srcu_idx)
-__acquires(&debugfs_srcu);
-
-void debugfs_use_file_finish(int srcu_idx) __releases(&debugfs_srcu);
-struct ib_umem *ib_umem_get_hfi(struct ib_ucontext *context, unsigned long addr,
-				size_t size, int access, int dmasync);
-
-static inline long compat_get_user_pages(unsigned long start,
-					 unsigned long nr_pages,
-					 unsigned int gup_flags,
-					 struct page **pages,
-					 struct vm_area_struct **vmas)
-{
-	return get_user_pages(current, current->mm, start,
-			      nr_pages, 1, 1, pages, vmas);
-}
-
-#define get_user_pages(start, nr_pages, gup_flags, pages, vmas) \
-	compat_get_user_pages(start, nr_pages, gup_flags, pages, vmas)
-
-static inline int simple_positive(struct dentry *dentry)
-{
-	return !d_unhashed(dentry) && dentry->d_inode;
-}
-
-static inline void hfi1_enable_intx(struct pci_dev *pdev)
-{
-	/* first, turn on INTx */
-	pci_intx(pdev, 1);
-	/* then turn off MSI-X */
-	pci_disable_msix(pdev);
-}
-
-/* Helpers to hide struct msi_desc implementation details */
-#define msi_desc_to_dev(desc)           ((desc)->dev)
-#define dev_to_msi_list(dev)            (&(dev)->msi_list)
-#define first_msi_entry(dev)            \
-	list_first_entry(dev_to_msi_list((dev)), struct msi_desc, list)
-#define for_each_msi_entry(desc, dev)   \
-	list_for_each_entry((desc), dev_to_msi_list((dev)), list)
 
-#endif //RH76_COMPAT
+
+#endif //DEB9_COMPAT
--- a/rdmavt/compat.c
+++ b/rdmavt/compat.c
@@ -58,49 +58,221 @@
 #include "../hfi1/hfi.h"
 #include "compat.h"
 
-/**
- * debugfs_use_file_start - mark the beginning of file data access
- * @dentry: the dentry object whose data is being accessed.
- * @srcu_idx: a pointer to some memory to store a SRCU index in.
- *
- * Up to a matching call to debugfs_use_file_finish(), any
- * successive call into the file removing functions debugfs_remove()
- * and debugfs_remove_recursive() will block. Since associated private
- * file data may only get freed after a successful return of any of
- * the removal functions, you may safely access it after a successful
- * call to debugfs_use_file_start() without worrying about
- * lifetime issues.
- *
- * If -%EIO is returned, the file has already been removed and thus,
- * it is not safe to access any of its data. If, on the other hand,
- * it is allowed to access the file data, zero is returned.
+
+#undef rdma_create_ah
+#undef rdma_destroy_ah
+
+struct ib_ah *rdma_create_ah(struct ib_pd *pd, struct rdma_ah_attr *ah_attr)
+{
+	struct ib_ah *ah;
+	ah = pd->device->create_ah(pd, ah_attr);
+	if (!IS_ERR(ah)) {
+		ah->device  = pd->device;
+		ah->pd      = pd;
+		ah->uobject = NULL;
+		atomic_inc(&pd->usecnt);
+	}
+	return ah;
+}
+EXPORT_SYMBOL(rdma_create_ah);
+
+//DMA
+/*
+ * The following functions implement driver specific replacements
+ * for the ib_dma_*() functions.
  *
- * Regardless of the return code, any call to
- * debugfs_use_file_start() must be followed by a matching call
- * to debugfs_use_file_finish().
+ * These functions return kernel virtual addresses instead of
+ * device bus addresses since the driver uses the CPU to copy
+ * data instead of using hardware DMA.
  */
-int debugfs_use_file_start(struct dentry *dentry, int *srcu_idx)
-	__acquires(&debugfs_srcu)
+static int rvt_mapping_error(struct ib_device *dev, u64 dma_addr)
 {
-	*srcu_idx = srcu_read_lock(&debugfs_srcu);
-	barrier();
-	if (d_unlinked(dentry))
-		return -EIO;
-	return 0;
+	return dma_addr == BAD_DMA_ADDRESS;
+}
+
+static u64 rvt_dma_map_single(struct ib_device *dev, void *cpu_addr,
+                              size_t size, enum dma_data_direction direction)
+{
+	if (WARN_ON(!valid_dma_direction(direction)))
+		return BAD_DMA_ADDRESS;
+	return (u64)cpu_addr;
+}
+
+static void rvt_dma_unmap_single(struct ib_device *dev, u64 addr, size_t size,
+                                 enum dma_data_direction direction)
+{
+	/* This is a stub, nothing to be done here */
+}
+
+static u64 rvt_dma_map_page(struct ib_device *dev, struct page *page,
+                            unsigned long offset, size_t size,
+                            enum dma_data_direction direction)
+{        u64 addr;
+
+	if (WARN_ON(!valid_dma_direction(direction)))
+		return BAD_DMA_ADDRESS;
+
+	addr = (u64)page_address(page);
+	if (addr)
+		addr += offset;
+
+	return addr;
+}
+
+static void rvt_dma_unmap_page(struct ib_device *dev, u64 addr, size_t size,
+                               enum dma_data_direction direction)
+{
+	/* This is a stub, nothing to be done here */
+}
+
+static int rvt_map_sg(struct ib_device *dev, struct scatterlist *sgl,
+                      int nents, enum dma_data_direction direction)
+{
+	struct scatterlist *sg;
+	u64 addr;
+	int i;        int ret = nents;
+
+	if (WARN_ON(!valid_dma_direction(direction)))
+		return 0;
+
+	for_each_sg(sgl, sg, nents, i) {
+		addr = (u64)page_address(sg_page(sg));
+		if (!addr) {
+			ret = 0;
+			break;
+		}
+		sg->dma_address = addr + sg->offset;
+#ifdef CONFIG_NEED_SG_DMA_LENGTH
+		sg->dma_length = sg->length;
+#endif
+	}
+	return ret;
+}
+
+static void rvt_unmap_sg(struct ib_device *dev,
+                         struct scatterlist *sg, int nents,
+                         enum dma_data_direction direction)
+{
+	/* This is a stub, nothing to be done here */
+}
+
+static int rvt_map_sg_attrs(struct ib_device *dev, struct scatterlist *sgl,
+                            int nents, enum dma_data_direction direction,
+                            unsigned long attrs)
+{
+	return rvt_map_sg(dev, sgl, nents, direction);
+}
+
+static void rvt_unmap_sg_attrs(struct ib_device *dev,
+                               struct scatterlist *sg, int nents,
+                               enum dma_data_direction direction,
+                               unsigned long attrs)
+{
+	return rvt_unmap_sg(dev, sg, nents, direction);
+}
+
+static void rvt_sync_single_for_cpu(struct ib_device *dev, u64 addr,
+                                    size_t size, enum dma_data_direction dir)
+{
+}
+
+static void rvt_sync_single_for_device(struct ib_device *dev, u64 addr,
+                                       size_t size,
+                                       enum dma_data_direction dir)
+{
+}
+
+static void *rvt_dma_alloc_coherent(struct ib_device *dev, size_t size,
+                                    u64 *dma_handle, gfp_t flag)
+{
+	struct page *p;
+	void *addr = NULL;
+
+	p = alloc_pages(flag, get_order(size));
+	if (p)
+		addr = page_address(p);
+	if (dma_handle)
+		*dma_handle = (u64)addr;
+	return addr;
+}
+
+static void rvt_dma_free_coherent(struct ib_device *dev, size_t size,
+                                  void *cpu_addr, u64 dma_handle)
+{
+	free_pages((unsigned long)cpu_addr, get_order(size));
+}
+
+/*
+ * We should only need to wait 100ms after FLR, but some devices take longer.
+ * Wait for up to 1000ms for config space to return something other than -1.
+ * Intel IGD requires this when an LCD panel is attached.  We read the 2nd
+ * dword because VFs don't implement the 1st dword.
+ */
+static void pci_flr_wait(struct pci_dev *dev)
+{
+	int i = 0;
+	u32 id;
+
+	do {
+		msleep(100);
+		pci_read_config_dword(dev, PCI_COMMAND, &id);
+	} while (i++ < 10 && id == ~0);
+
+	if (id == ~0)
+		dev_warn(&dev->dev, "Failed to return from FLR\n");
+	else if (i > 1)
+		dev_info(&dev->dev, "Required additional %dms to return from FLR\n",
+				 (i - 1) * 100);
 }
-EXPORT_SYMBOL(debugfs_use_file_start);
 
 /**
- * debugfs_use_file_finish - mark the end of file data access
- * @srcu_idx: the SRCU index "created" by a former call to
- *            debugfs_use_file_start().
+ * pcie_flr - initiate a PCIe function level reset
+ *  @dev:        device to reset
  *
- * Allow any ongoing concurrent call into debugfs_remove() or
- * debugfs_remove_recursive() blocked by a former call to
- * debugfs_use_file_start() to proceed and return to its caller.
+ * Initiate a function level reset on @dev.  The caller should ensure the
+ * device supports FLR before calling this function, e.g. by using the
+ * pcie_has_flr() helper.
  */
-void debugfs_use_file_finish(int srcu_idx) __releases(&debugfs_srcu)
+void pcie_flr(struct pci_dev *dev)
 {
-	srcu_read_unlock(&debugfs_srcu, srcu_idx);
+	if (!pci_wait_for_pending_transaction(dev)) {
+		dev_err(&dev->dev,
+				"timed out waiting for pending transaction; performing function level reset anyway\n");
+	}
+	pcie_capability_set_word(dev,
+							 PCI_EXP_DEVCTL,
+							 PCI_EXP_DEVCTL_BCR_FLR);
+	pci_flr_wait(dev);
 }
-EXPORT_SYMBOL(debugfs_use_file_finish);
+EXPORT_SYMBOL_GPL(pcie_flr);
+
+int rdma_destroy_ah(struct ib_ah *ah)
+{
+	struct ib_pd *pd;
+	int ret;
+
+	pd = ah->pd;
+	ret = ah->device->destroy_ah(ah);
+	if (!ret) {
+		atomic_dec(&pd->usecnt);
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL(rdma_destroy_ah);
+
+struct ib_dma_mapping_ops rvt_default_dma_mapping_ops = {
+	.mapping_error = rvt_mapping_error,
+	.map_single = rvt_dma_map_single,
+	.unmap_single = rvt_dma_unmap_single,
+	.map_page = rvt_dma_map_page,
+	.unmap_page = rvt_dma_unmap_page,
+	.map_sg = rvt_map_sg,
+	.unmap_sg = rvt_unmap_sg,
+	.map_sg_attrs = rvt_map_sg_attrs,
+	.unmap_sg_attrs = rvt_unmap_sg_attrs,
+	.sync_single_for_cpu = rvt_sync_single_for_cpu,
+	.sync_single_for_device = rvt_sync_single_for_device,
+	.alloc_coherent = rvt_dma_alloc_coherent,
+	.free_coherent = rvt_dma_free_coherent
+};
--- a/include/rdma/rdma_vt.h
+++ b/include/rdma/rdma_vt.h
@@ -204,6 +204,10 @@
 };
 
 
+/*
+ * NOTE: do not define HAVE_IB_QP_CREATE_USE_GFP_NOIO for IFS_DEB9. Doing so
+ * causes qp creation from IPoIB to fail.
+ */
 #define HAVE_IB_QP_CREATE_USE_GFP_NOIO \
 	(defined(IFS_RH73) || \
 	defined(IFS_RH74) || \
--- a/rdmavt/vt.c
+++ b/rdmavt/vt.c
@@ -625,7 +625,7 @@
 	spin_lock_init(&rdi->n_cqs_lock);
 
 	/* DMA Operations */
-#if !defined(IFS_RH73) && !defined(IFS_RH74) && !defined(IFS_RH75) && !defined(IFS_RH76) && !defined(IFS_RH77) && !defined(IFS_SLES12SP2) && !defined(IFS_SLES12SP3)
+#if !defined(IFS_RH73) && !defined(IFS_RH74) && !defined(IFS_RH75) && !defined(IFS_RH76) && !defined(IFS_RH77) && !defined(IFS_SLES12SP2) && !defined(IFS_SLES12SP3) && !defined(IFS_DEB9)
 	rdi->ibdev.dev.dma_ops = rdi->ibdev.dev.dma_ops ? : &dma_virt_ops;
 #elif defined(IFS_RH75) || defined(IFS_RH76) || defined(IFS_RH77)
 	rdi->ibdev.dev.device_rh->dma_ops =
--- a/rdmavt/Makefile
+++ b/rdmavt/Makefile
@@ -7,7 +7,7 @@
 ifneq ($(KERNELRELEASE),)
 #kbuild part of makefile
 
-NOSTDINC_FLAGS += -I${M}/include -I${M}/compat
+NOSTDINC_FLAGS += -I${M}/include -I${M}/include/uapi -I${M}/compat
 
 obj-$(CONFIG_INFINIBAND_RDMAVT) += rdmavt.o
 
--- a/rdmavt/compat_common.c
+++ b/rdmavt/compat_common.c
@@ -200,7 +200,7 @@
 	SET_DEVICE_OP(dev_ops, alloc_mr);
 	SET_DEVICE_OP(dev_ops, alloc_mw);
 	SET_DEVICE_OP(dev_ops, alloc_pd);
-#ifdef HAVE_ALLOC_RDMA_NETDEV
+#if defined(HAVE_ALLOC_RDMA_NETDEV) && !defined(IFS_DEB9)
 	SET_DEVICE_OP(dev_ops, alloc_rdma_netdev);
 #endif
 	SET_DEVICE_OP(dev_ops, alloc_ucontext);
@@ -337,3 +337,4 @@
 }
 EXPORT_SYMBOL(ib_set_device_ops);
 #endif
+
--- a/include/uapi/rdma/rdma_user_ioctl.h
+++ b/include/uapi/rdma/rdma_user_ioctl.h
@@ -38,9 +38,10 @@
 #include <rdma/hfi/hfi1_ioctl.h>
 #include <rdma/rdma_user_ioctl_cmds.h>
 
+#ifndef IB_IOCTL_MAGIC
 /* Legacy name, for user space application which already use it */
 #define IB_IOCTL_MAGIC		RDMA_IOCTL_MAGIC
-
+#endif
 /*
  * General blocks assignments
  * It is closed on purpose do not expose it it user space
@@ -49,10 +50,18 @@
  */
 
 /* MAD specific section */
+#ifndef IB_USER_MAD_REGISTER_AGENT
 #define IB_USER_MAD_REGISTER_AGENT	_IOWR(RDMA_IOCTL_MAGIC, 0x01, struct ib_user_mad_reg_req)
+#endif
+#ifndef IB_USER_MAD_UNREGISTER_AGENT
 #define IB_USER_MAD_UNREGISTER_AGENT	_IOW(RDMA_IOCTL_MAGIC,  0x02, __u32)
+#endif
+#ifndef IB_USER_MAD_ENABLE_PKEY
 #define IB_USER_MAD_ENABLE_PKEY		_IO(RDMA_IOCTL_MAGIC,   0x03)
+#endif
+#ifndef IB_USER_MAD_REGISTER_AGENT2
 #define IB_USER_MAD_REGISTER_AGENT2	_IOWR(RDMA_IOCTL_MAGIC, 0x04, struct ib_user_mad_reg_req2)
+#endif
 
 /* HFI specific section */
 /* allocate HFI and context */
